# -*- coding: utf-8 -*-
"""Googleplaystore_EDA_Predictive_Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tq20Aqcklpd7WlTi3ljDPuZlMmTGpLB3
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("googleplaystore.csv")

df.head()

df.columns

df.info()

df.isnull().sum()

"""Data Cleaning"""

x=df.Rating.mean()
df.Rating.fillna(x,inplace=True)

df.isnull().sum()

print(df[df.Rating>5])

df.drop([10472],inplace=True)

df.isnull().sum()

df.Rating.max()

df.Installs

# Converting installs from string to floating point
df["Installs"] = df.Installs.apply(lambda x: str(x).replace("+",""))
df["Installs"] = df.Installs.apply(lambda x: str(x).replace(",",""))
df["Installs"] = df.Installs.apply(lambda x: float(x))
df.Installs.dtype

df.Installs

df.Price.unique()

df["Price"] = df.Price.apply(lambda x: str(x).replace("$", ""))
df["Price"] = df.Price.apply(lambda x: float(x))
df.Price.dtype

df.Reviews.unique()
df["Reviews"] = df.Reviews.apply(lambda x: int(x))

df.head()

"""Data Visualization

Most Installed Apps
"""

sns.set_style("whitegrid")
x=df.groupby("App").Installs.sum().sort_values(ascending=False).head(10)
sns.barplot(x.values,x.index)

"""Top paid Apps"""

x=df[df["Type"]=="Paid"]
y=x.groupby("App").Installs.sum().sort_values(ascending=False).head(10)
sns.barplot(y.values,y.index)

"""Top Free Apps"""

x=df[df["Type"]=="Free"]
y=x.groupby("App").Installs.sum().sort_values(ascending=False).head(10)
sns.barplot(y.values,y.index)

"""Type Pie Chart"""

x=df.Type.value_counts()
label=["Paid","Free"]
plt.pie(x,labels=label,autopct="%1.1f%%")
plt.show()

"""Installs vs Rating"""

sns.lmplot(x="Rating",y="Installs",data=df)

"""Category Pie chart"""

df.Category.unique()
x=df.Category.value_counts()
label = list(x.index)
plt.figure(figsize=(15,15))
plt.pie(x,labels=label,autopct="%1.1f%%")
plt.show()

"""Genres Count"""

plt.figure(figsize=(20,10))
ax=sns.countplot(x="Genres",data=df)
ax.set_xticklabels(ax.get_xticklabels(),rotation=90)
plt.show

"""Top Rated Category"""

df.groupby("Category").Rating.mean().sort_values(ascending = False)

"""Top Rated Genres"""

df.groupby("Genres").Rating.mean().sort_values(ascending = False)

"""Least Rated Category"""

df.groupby("Category").Rating.mean().sort_values(ascending=True).head(10)

"""Least Rated Genres"""

df.groupby("Genres").Rating.mean().sort_values(ascending=True).head(10)

"""Content Rating vs Rating"""

plt.figure(figsize=(10,10))
ax=sns.boxplot(x="Content Rating",y="Rating",data=df)
ax.set_xticklabels(ax.get_xticklabels(),rotation=45)
plt.show()

"""Categories with the most Installs"""

df.groupby("Category").Installs.sum().sort_values(ascending=False).head()

"""Predective Analytics"""

df.drop(labels=["Current Ver","Android Ver","App"],axis=1,inplace=True)

"""Convert categorical variables to numeric so that they can work smoothly with machine learning
algorithms.
"""

category_list = df['Category'].unique().tolist()
category_list = ['cat_' + word for word in category_list]
df = pd.concat([df, pd.get_dummies(df['Category'], prefix = 'cat')], axis = 1)

df.head()

"""Encoding Genres"""

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
df['Genres'] = le.fit_transform(df['Genres'])
df['Genres']

df['Content Rating'].unique()

import statistics
statistics.mode(df['Content Rating'])

df['Content Rating'] = df['Content Rating'].replace(0, 'Everyone')

df['Content Rating'] = df['Content Rating'].replace(np.nan, 'Unrated')

"""Encoding Content Rating"""

le = preprocessing.LabelEncoder()
df['Content Rating'] = le.fit_transform(df['Content Rating'])

df["Size"] = [str(round(float(i.replace("k", ""))/1024, 3)) if "k" in i else i for i in df.Size]

df['Size'] = df['Size'].replace('1,000+', 0)

df["Size"] = df.Size.apply(lambda x: str(x).replace("M", "000"))

df["Size"] = df.Size.apply(lambda x: str(x).replace("k", ""))

df[df['Size'] == 'Varies with device'] = 0
df['Size'] = df['Size'].astype(float)

df['new'] = pd.to_datetime(df['Last Updated'])
df['lastupdate'] = (df['new'] - df['new'].max()).dt.days

df=pd.concat([df, pd.get_dummies(df['Type'])], axis=1)

df

df.columns

x = df.drop(labels=["Rating", "Category", "Last Updated","Type","new"], axis = 1)
y = df['Rating']

x

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

"""Modelling"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 42)

"""Linear Regression"""

multiple_linear_regression = LinearRegression()
multiple_linear_regression.fit(x_train, y_train)

accuracy = multiple_linear_regression.score(x_test, y_test)
'Accuracy: ' + str(np.round(accuracy*100, 2)) + '%'

"""K-Nearest Neighbours"""

knn = KNeighborsRegressor(n_neighbors = 25)
knn.fit(x_train, y_train)

accuracy = knn.score(x_test, y_test)
'Accuracy: ' + str(np.round(accuracy*100, 2)) + '%'

n_neighbors = np.arange(1, 40, 1)
scores = []
for n in n_neighbors:
  knn.set_params(n_neighbors = n)
  knn.fit(x_train, y_train)
  scores.append(knn.score(x_test, y_test))


plt.figure(figsize = (7, 5))
plt.title("Effect of Estimators")
plt.xlabel("Number of Neighbors K")
plt.ylabel("Score")
plt.plot(n_neighbors, scores)

print("max accuracy is: ", max(scores))
print("K value to achieve this result: ", n_neighbors[scores.index(max(scores))])

"""Decision Tree"""

tree_reg = DecisionTreeRegressor()
tree_reg.fit(x_train, y_train)

accuracy = tree_reg.score(x_test, y_test)
'Accuracy: ' + str(np.round(accuracy*100, 2)) + '%'

"""Random Forest"""

rf = RandomForestRegressor(n_jobs = -1)
estimators = np.arange(10, 150, 10)
scores = []
for n in estimators:
  rf.set_params(n_estimators = n)
  rf.fit(x_train, y_train)
  scores.append(rf.score(x_test, y_test))
plt.figure(figsize = (7, 5))
plt.title("Effect of Estimators")
plt.xlabel("no. estimator")
plt.ylabel("score")
plt.plot(estimators, scores)

print("max accuracy is: ", max(scores))

print("the number of estimators required to achieve this result: ", estimators[scores.index(max(scores))])

"""K Means Clustering"""

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters = 2, random_state = 0).fit(x_train)
kmeans.labels_
kmeans.predict(x_test)

centroids = kmeans.cluster_centers_
print(centroids)

"""DBSCAN"""

from sklearn.cluster import DBSCAN
import numpy as np
clustering = DBSCAN(eps = 3).fit(x_train)

clustering.labels_

clustering.fit_predict(x_test)

clustering.get_params(deep = True)
